{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colorization.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXZhUGrNtbLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 256, 256\n",
        "channel = 3\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "patience = 50\n",
        "num_train_samples = 1000\n",
        "num_valid_samples = 200\n",
        "num_classes = 313\n",
        "kernel = 3\n",
        "weight_decay = 1e-1\n",
        "epsilon = 1e-8\n",
        "nb_neighbors = 5\n",
        "# temperature parameter T\n",
        "T = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUE0wmjGc-A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import multi_gpu_model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "l2_reg = l2(1e-3)\n",
        "\n",
        "def build_model():\n",
        "    input_tensor = Input(shape=(img_rows, img_cols, 1))\n",
        "    x = Conv2D(64, (kernel, kernel), activation='relu', padding='same', name='conv1_1', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg)(input_tensor)\n",
        "    x = Conv2D(64, (kernel, kernel), activation='relu', padding='same', name='conv1_2', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg, strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv2_1', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv2_2', kernel_initializer=\"he_normal\",\n",
        "               kernel_regularizer=l2_reg,\n",
        "               strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_2',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv3_3', kernel_initializer=\"he_normal\",\n",
        "               strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_2',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', name='conv4_3',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_2',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv5_3',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_2',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(512, (kernel, kernel), activation='relu', padding='same', dilation_rate=2, name='conv6_3',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_2',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(256, (kernel, kernel), activation='relu', padding='same', name='conv7_3',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_1',\n",
        "               kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_2',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    # x = Conv2D(128, (kernel, kernel), activation='relu', padding='same', name='conv8_3',\n",
        "    #            kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax', padding='same', name='pred')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=outputs, name=\"ColorNet\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfs5HaLWhKRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sklearn.neighbors as nn\n",
        "from keras.utils import Sequence\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "def get_soft_encoding(image_ab, nn_finder, nb_q):\n",
        "    h, w = image_ab.shape[:2]\n",
        "    a = np.ravel(image_ab[:, :, 0])\n",
        "    b = np.ravel(image_ab[:, :, 1])\n",
        "    ab = np.vstack((a, b)).T\n",
        "    # Get the distance to and the idx of the nearest neighbors\n",
        "    dist_neighb, idx_neigh = nn_finder.kneighbors(ab)\n",
        "    # Smooth the weights with a gaussian kernel\n",
        "    sigma_neighbor = 5\n",
        "    wts = np.exp(-dist_neighb ** 2 / (2 * sigma_neighbor ** 2))\n",
        "    wts = wts / np.sum(wts, axis=1)[:, np.newaxis]\n",
        "    # format the tar get\n",
        "    y = np.zeros((ab.shape[0], nb_q))\n",
        "    idx_pts = np.arange(ab.shape[0])[:, np.newaxis]\n",
        "    y[idx_pts, idx_neigh] = wts\n",
        "    y = y.reshape(h, w, nb_q)\n",
        "    return y\n",
        "\n",
        "\n",
        "class DataGenSequence(Sequence):\n",
        "    def __init__(self, usage):\n",
        "        self.usage = usage\n",
        "\n",
        "        if usage == 'train':\n",
        "            images = x_train[0:40000]\n",
        "        else:\n",
        "            images = x_train[40001:50000]\n",
        "\n",
        "\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "        # Load the array of quantized ab value\n",
        "        q_ab = np.load(\"/content/pts_in_hull.npy\")\n",
        "        self.nb_q = q_ab.shape[0]\n",
        "        # Fit a NN to q_ab\n",
        "        self.nn_finder = nn.NearestNeighbors(n_neighbors=nb_neighbors, algorithm='ball_tree').fit(q_ab)\n",
        "\n",
        "    def __len__(self):\n",
        "       return int(np.ceil(40000 / float(batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        i = idx * batch_size\n",
        "\n",
        "        out_img_rows, out_img_cols = img_rows // 4, img_cols // 4\n",
        "\n",
        "        length = min(batch_size, (40000 - i))\n",
        "        batch_x = np.empty((length, img_rows, img_cols, 1), dtype=np.float32)\n",
        "        batch_y = np.empty((length, out_img_rows, out_img_cols, self.nb_q), dtype=np.float32)\n",
        "\n",
        "        for i_batch in range(length):\n",
        "            #name = self.names[i]\n",
        "            #filename = os.path.join(image_folder, name)\n",
        "            # b: 0 <=b<=255, g: 0 <=g<=255, r: 0 <=r<=255.\n",
        "            #bgr = cv.imread(filename)\n",
        "            # bgr = cv.resize(bgr, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "            gray = cv.cvtColor(x_train[i], cv.COLOR_BGR2GRAY)\n",
        "            gray = cv.resize(gray, (256, 256))\n",
        "            # gray = cv.resize(gray, (img_rows, img_cols), cv.INTER_CUBIC)\n",
        "            lab = cv.cvtColor(x_train[i], cv.COLOR_BGR2LAB)\n",
        "            lab = cv.resize(lab, (256, 256))\n",
        "            x = gray / 255.\n",
        "\n",
        "            out_lab = cv.resize(lab, (out_img_rows, out_img_cols), cv.INTER_CUBIC)\n",
        "            # Before: 42 <=a<= 226, 20 <=b<= 223\n",
        "            # After: -86 <=a<= 98, -108 <=b<= 95\n",
        "            out_ab = out_lab[:, :, 1:].astype(np.int32) - 128\n",
        "\n",
        "            y = get_soft_encoding(out_ab, self.nn_finder, self.nb_q)\n",
        "\n",
        "            if np.random.random_sample() > 0.5:\n",
        "                x = np.fliplr(x)\n",
        "                y = np.fliplr(y)\n",
        "\n",
        "            batch_x[i_batch, :, :, 0] = x\n",
        "            batch_y[i_batch] = y\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(x_train)\n",
        "\n",
        "\n",
        "def train_gen():\n",
        "    return DataGenSequence('train')\n",
        "\n",
        "\n",
        "def valid_gen():\n",
        "    return DataGenSequence('valid')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS6Mpol_dctt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import multi_gpu_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from utils import get_available_gpus, categorical_crossentropy_color\n",
        "checkpoint_models_path = 'data/'\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "# tensor_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
        "# model_names = checkpoint_models_path + 'model.{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "# model_checkpoint = ModelCheckpoint(model_names, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "# early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "# reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience / 4), verbose=1)\n",
        "\n",
        "model = build_model()\n",
        "sgd = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True, clipnorm=5.)\n",
        "model.compile(optimizer=sgd, loss='mean_squared_error')\n",
        "#print(model.summary())\n",
        "# Final callbacks\n",
        "#callbacks = [tensor_board, model_checkpoint, early_stop, reduce_lr]\n",
        "\n",
        "# Start Fine-tuning\n",
        "history = model.fit_generator(train_gen(),\n",
        "                        steps_per_epoch=num_train_samples,\n",
        "                        validation_data=valid_gen(),\n",
        "                        validation_steps=num_valid_samples,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        # callbacks=callbacks,\n",
        "                        # use_multiprocessing=True,\n",
        "                        # workers=8\n",
        "                        )\n",
        "plt.plot(history.history['loss'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx7DXT_xJeMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x=train_gen(), batch_size=None, verbose=1, sample_weight=None, steps=100, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bjYCFuNLqN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(valid_gen(), verbose=0, steps=10, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}